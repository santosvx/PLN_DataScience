{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP tasks using TextBlob\n",
    "## Tokenization\n",
    "### Tokenization refers to dividing text or a sentence into a sequence of tokens, which roughly correspond to “words”. This is one of the basic tasks of NLP. To do this using TextBlob, follow the two steps:\n",
    "\n",
    "# Create a textblob object and pass a string with it.\n",
    "# Call functions of textblob in order to do a specific task.\n",
    "\n",
    "# So, let’s quickly create a textblob object to play with.\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "blob = TextBlob(\"Analytics Vidhya is a great platform to learn data science. \\n It helps community through blogs, hackathons, discussions,etc.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Analytics Vidhya is a great platform to learn data science.\"),\n",
       " Sentence(\"It helps community through blogs, hackathons, discussions,etc.\")]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, this textblob can be tokenized into a sentence and further into words. Let’s look at the code shown below.\n",
    "blob.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence(\"Analytics Vidhya is a great platform to learn data science.\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting only first sentence\n",
    "blob.sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytics\n",
      "Vidhya\n",
      "is\n",
      "a\n",
      "great\n",
      "platform\n",
      "to\n",
      "learn\n",
      "data\n",
      "science\n"
     ]
    }
   ],
   "source": [
    "# printing words of first sentence\n",
    "for words in blob.sentences[0].words:\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analytics vidhya\n",
      "great platform\n",
      "data science\n"
     ]
    }
   ],
   "source": [
    "# Noun Phrase Extraction\n",
    "# Since we extracted the words in the previous section, instead of that we can just extract out the noun phrases from the textblob. Noun Phrase extraction is particularly important when you want to analyze the “who” in a sentence. Lets see an example below.\n",
    "\n",
    "blob = TextBlob(\"Analytics Vidhya is a great platform to learn data science.\")\n",
    "\n",
    "for np in blob.noun_phrases:\n",
    " print (np)\n",
    "\n",
    "# As we can see that the results aren’t perfectly correct, but we should be aware that we are working with machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytics NNS\n",
      "Vidhya NNP\n",
      "is VBZ\n",
      "a DT\n",
      "great JJ\n",
      "platform NN\n",
      "to TO\n",
      "learn VB\n",
      "data NNS\n",
      "science NN\n"
     ]
    }
   ],
   "source": [
    "# Part-of-speech Tagging\n",
    "# Part-of-speech tagging or grammatical tagging is a method to mark words present in a text on the basis of its definition and context. In simple words, it tells whether a word is a noun, or an adjective, or a verb, etc. This is just a complete version of noun phrase extraction, where we want to find all the the parts of speech in a sentence.\n",
    "\n",
    "# Let’s check the tags of our textblob.\n",
    "\n",
    "for words, tag in blob.tags:\n",
    " print (words, tag)\n",
    "\n",
    "# Here, NN represents a noun, DT represents as a determiner, etc. You can check the full list of tags from here to know more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helps\n",
      "help\n"
     ]
    }
   ],
   "source": [
    "# Words Inflection and Lemmatization\n",
    "# Inflection is a process of word formation in which characters are added to the base form of a word to express grammatical meanings. Word inflection in TextBlob is very simple, i.e., the words we tokenized from a textblob can be easily changed into singular or plural.\n",
    "\n",
    "blob = TextBlob(\"Analytics Vidhya is a great platform to learn data science. \\n It helps community through blogs, hackathons, discussions,etc.\")\n",
    "print (blob.sentences[1].words[1])\n",
    "print (blob.sentences[1].words[1].singularize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Platforms'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TextBlob library also offers an in-build object known as Word. We just need to create a word object and then apply a function directly to it as shown below.\n",
    "\n",
    "from textblob import Word\n",
    "w = Word('Platform')\n",
    "w.pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "platforms\n",
      "sciences\n",
      "communities\n"
     ]
    }
   ],
   "source": [
    "# We can also use the tags to inflect a particular type of words as shown below.\n",
    "\n",
    "# using tags\n",
    "for word,pos in blob.tags:\n",
    " if pos == 'NN':\n",
    "     print (word.pluralize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words can be lemmatized using the lemmatize function.\n",
    "\n",
    "# lemmatization\n",
    "w = Word('running')\n",
    "# v here represents verb\n",
    "w.lemmatize(\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Analytics', 'Vidhya']\n",
      "['Vidhya', 'is']\n",
      "['is', 'a']\n",
      "['a', 'great']\n",
      "['great', 'platform']\n",
      "['platform', 'to']\n",
      "['to', 'learn']\n",
      "['learn', 'data']\n",
      "['data', 'science']\n",
      "['science', 'It']\n",
      "['It', 'helps']\n",
      "['helps', 'community']\n",
      "['community', 'through']\n",
      "['through', 'blogs']\n",
      "['blogs', 'hackathons']\n",
      "['hackathons', 'discussions']\n",
      "['discussions', 'etc']\n"
     ]
    }
   ],
   "source": [
    "# N-grams\n",
    "# A combination of multiple words together are called N-Grams. N grams (N > 1) are generally more informative as compared to words, and can be used as features for language modelling.  N-grams can be easily accessed in TextBlob using the ngrams function, which returns a tuple of n successive words.\n",
    "\n",
    "for ngram in blob.ngrams(2):\n",
    "    print (ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytics Vidhya is a great platform to learn data science. \n",
      " It helps community through blogs, hackathons, discussions,etc.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.8, subjectivity=0.75)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment Analysis\n",
    "# Sentiment analysis is basically the process of determining the attitude or the emotion of the writer, i.e., whether it is positive or negative or neutral.\n",
    "\n",
    "# The sentiment function of textblob returns two properties, polarity, and subjectivity.\n",
    "\n",
    "# Polarity is float which lies in the range of [-1,1] where 1 means positive statement and -1 means a negative statement. Subjective sentences generally refer to personal opinion, emotion or judgment whereas objective refers to factual information. Subjectivity is also a float which lies in the range of [0,1].\n",
    "\n",
    "# Let’s check the sentiment of our blob.\n",
    "\n",
    "print (blob)\n",
    "blob.sentiment\n",
    "\n",
    "# We can see that polarity is 0.8, which means that the statement is positive and 0.75 subjectivity refers that mostly it is a public opinion and not a factual information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Analytics Vidhya is a great platform to learn data science\")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Other cool things to do\n",
    "# Spelling Correction\n",
    "# Spelling correction is a cool feature which TextBlob offers, we can be accessed using the correct function as shown below.\n",
    "\n",
    "blob = TextBlob('Analytics Vidhya is a gret platfrm to learn data scence')\n",
    "blob.correct()\n",
    "\n",
    "# We can also check the list of suggested word and its confidence using the spellcheck function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.5351351351351351),\n",
       " ('get', 0.3162162162162162),\n",
       " ('grew', 0.11216216216216217),\n",
       " ('grey', 0.026351351351351353),\n",
       " ('greet', 0.006081081081081081),\n",
       " ('fret', 0.002702702702702703),\n",
       " ('grit', 0.0006756756756756757),\n",
       " ('cret', 0.0006756756756756757)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words[4].spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a short summary of a text\n",
    "# This is a simple trick which we will be using the things we learned above. First, take a look at the code shown below and to understand yourself.\n",
    "\n",
    "import random\n",
    "\n",
    "blob = TextBlob('Analytics Vidhya is a thriving community for data driven industry. This platform allows \\\n",
    "people to know more about analytics from its articles, Q&A forum, and learning paths. Also, we help \\\n",
    "professionals & amateurs to sharpen their skillsets by providing a platform to participate in Hackathons.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This text is about...\n",
      "platforms\n",
      "industries\n",
      "platforms\n",
      "forums\n",
      "communities\n"
     ]
    }
   ],
   "source": [
    "nouns = list()\n",
    "for word, tag in blob.tags:\n",
    "    if tag == 'NN':\n",
    "        nouns.append(word.lemmatize())\n",
    "\n",
    "print (\"This text is about...\")\n",
    "for item in random.sample(nouns, 5):\n",
    "    word = Word(item)\n",
    "    print (word.pluralize())\n",
    "        \n",
    "# Simple, Ain’t it? What we did above that we extracted out a list of nouns from the text to give a general idea to the reader about the things the text is related to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Translation and Language Detection\n",
    "# Can you guess what is written in the next line?\n",
    "\n",
    "# Haha! Can you guess which language is this? Don’t worry, let’s detect it using textblob…\n",
    "\n",
    "blob.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Analytics Vidhya é uma comunidade próspera para a indústria baseada em dados. Essa plataforma permite que as pessoas conheçam mais sobre análise de seus artigos, fórum de perguntas e respostas e caminhos de aprendizado. Além disso, ajudamos os profissionais e amadores a aprimorar suas habilidades fornecendo uma plataforma para participar de Hackathons.\")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So, it is English. Now, let’s find translate it into Portugues so that we can know what is written using TextBlob.\n",
    "\n",
    "blob.translate(from_lang='en', to ='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Analytics Vidhya es una comunidad próspera para la industria basada en datos. Esta plataforma permite a las personas saber más sobre análisis de sus artículos, foro de preguntas y respuestas y rutas de aprendizaje. Además, ayudamos a profesionales y aficionados a mejorar sus habilidades proporcionando una plataforma para participar en Hackathons.\")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Even if you don’t explicitly define the source language, TextBlob will automatically detect the language and translate into the desired language.\n",
    "\n",
    "## or you can directly do like this\n",
    "blob.translate(to= 'es')\n",
    "\n",
    "# This is seriously so cool!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text classification using TextBlob\n",
    "# Let’s build a simple text classification model using TextBlob. For this, first, we need to prepare a training and testing data.\n",
    "\n",
    "training = [\n",
    "('Tom Holland is a terrible spiderman.','pos'),\n",
    "('a terrible Javert (Russell Crowe) ruined Les Miserables for me...','pos'),\n",
    "('The Dark Knight Rises is the greatest superhero movie ever!','neg'),\n",
    "('Fantastic Four should have never been made.','pos'),\n",
    "('Wes Anderson is my favorite director!','neg'),\n",
    "('Captain America 2 is pretty awesome.','neg'),\n",
    "('Let\\s pretend \"Batman and Robin\" never happened..','pos'),\n",
    "]\n",
    "\n",
    "testing = [\n",
    "('Superman was never an interesting character.','pos'),\n",
    "('Fantastic Mr Fox is an awesome film!','neg'),\n",
    "('Dragonball Evolution is simply terrible!!','pos')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textblob provides in-build classifiers module to create a custom classifier. So, let’s quickly import it and create a basic classifier.\n",
    "\n",
    "from textblob import classifiers\n",
    "classifier = classifiers.NaiveBayesClassifier(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you can see above, we have passed the training data into the classifier.\n",
    "\n",
    "# Note that here we have used Naive Bayes classifier, but TextBlob also offers Decision tree classifier which is as shown below.\n",
    "\n",
    "## decision tree classifier\n",
    "dt_classifier = classifiers.DecisionTreeClassifier(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Most Informative Features\n",
      "            contains(is) = True              neg : pos    =      2.9 : 1.0\n",
      "         contains(never) = False             neg : pos    =      1.8 : 1.0\n",
      "             contains(a) = False             neg : pos    =      1.8 : 1.0\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "# Now, let’s check the accuracy of this classifier on the testing dataset and also TextBlob provides us to check the most informative features.\n",
    "\n",
    "print (classifier.accuracy(testing))\n",
    "classifier.show_informative_features(3)\n",
    "\n",
    "# As, we can see that if the text contains “is”, then there is a high probability that the statement will be negative.\n",
    "\n",
    "# In order to give a little more idea, let’s check our classifier on a random text.\n",
    "\n",
    "blob = TextBlob('the weather is terrible!', classifier=classifier)\n",
    "print (blob.classify())\n",
    "\n",
    "# So, based on the training on the above dataset, our classifier has provided us the right result.\n",
    "\n",
    "# Note that here we could have done some preprocessing and data cleaning but here my aim was to give you an intuition that how we can do text classification using TextBlob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pros and Cons\n",
    "\n",
    "# Pros:\n",
    "#  Since, it is built on the shoulders of NLTK and Pattern, therefore making it simple for beginners by providing an intuitive interface to NLTK.\n",
    "# It provides language translation and detection which is powered by Google Translate ( not provided with Spacy).\n",
    "\n",
    "#  Cons:\n",
    "#  It is little slower in the comparison to spacy but faster than NLTK. (Spacy > TextBlob > NLTK)\n",
    "#  It does not provide features like dependency parsing, word vectors etc. which is provided by spacy.\n",
    " \n",
    "\n",
    "# End Notes\n",
    "# I hope that you that a fun time learning about this library. TextBlob, actually provided a very easy interface for beginners to learn basic NLP tasks.\n",
    "\n",
    "# I would recommend every beginner to start with this library and then in order to do advance work you can learn spacy as well. We will still be using TextBlob for initial prototyping in the almost every NLP project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
